{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    "table {float:left}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%javascript\n",
    "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id=\"tocheading\">Overview</h1>\n",
    "<div id=\"toc\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Learn and understand MongoDB and how to use it from Python\n",
    "* Learn and understand Twitter REST and streaming APIs and how to use them from Python\n",
    "* Understand what Sentiment Analysis is\n",
    "* Build a twitter sentiment mining application\n",
    "* Learn how to deploy a data science product as an API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Road Ahead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Mining Twitter Sentiment\n",
    "* NBC for Spam and Ham\n",
    "* Kaggle Titanic Competition\n",
    "* SQL in the Wild!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Scheme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 10% for submission of Assignment 1 (bdap2015/NoSQL)\n",
    "* 40% for submission of Assignment 2\n",
    "* 50% for final exam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Twitter Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Twitter - learn to use rest and streaming apis\n",
    "* Twitter - perfect data structure to learn mongodb\n",
    "* Sentiment Analysis - introduction to machine learning and natural language processing\n",
    "* Sentiment Analysis - we'll keep revisiting as we learn more and more sophisticated techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to MongoDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CRUD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create/Insert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "    mongo twitter\n",
    "    \n",
    "    db.users.insert({\n",
    "      name: \"Shakuny Mama\",\n",
    "      email: \"shakuni.mama@mahabharata.com\",\n",
    "      age:42\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    show collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    db.users.find()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes**\n",
    "* Databases and Collections are lazily created - created when we need them, not when they are defined.\n",
    "* With greater flexibility comes greater responsibility - beware of typos\n",
    "\n",
    "**Note: What is special about _id?**\n",
    "* Auto-generated\n",
    "* Auto-generated vs Auto-incremented\n",
    "* Horizontal Sharding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "    db.users.find({ \"_id\" : ObjectId(\"566a247ddae35821b3a0c523\") })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(select fields)\n",
    "\n",
    "    db.users.find({ _id : ObjectId(\"566a247ddae35821b3a0c523\") }, { name : 1 })\n",
    "    db.users.find({ _id : ObjectId(\"566a247ddae35821b3a0c523\") }, { name : 0 }) #omit only name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(more sophisticated queries)\n",
    "\n",
    "    db.users.find(\n",
    "        { name : /^P/, age : { $lt : 40 } },\n",
    "        { name : 1, age : 1 }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(an even more complicated example)\n",
    "\n",
    "    var age_range = {}\n",
    "    age_range['$lt'] = 1000000\n",
    "    age_range['$gt'] = 10000\n",
    "    \n",
    "    db.users.find(\n",
    "        { name : /^P/, age : age_range },\n",
    "        { name: 1 }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "    db.users.update(\n",
    "        { _id : ObjectId(\"4d0ada87bb30773266f39fe5\") },\n",
    "        { $set : { \"name\" : \"Something Else\" } }\n",
    "    );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "    var bad_bacon = {\n",
    "        'exports.foods' : {\n",
    "            $elemMatch : {\n",
    "                name : 'bacon',\n",
    "                tasty : false\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    db.countries.find( bad_bacon )\n",
    "\n",
    "    db.countries.remove( bad_bacon )\n",
    "    db.countries.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"mongodb_record_as_json_diag.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A quick comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"sql_vs_mongodb_schema_arrangement.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Concept | SQL | MongoDB |\n",
    "|:---|---|---|\n",
    "| One User                         | One Row                    | One Document |\n",
    "| All Users                        | Users Table                | Users Collection |\n",
    "| One Username Per User (1-to-1)   | Username Column            | Username Property |\n",
    "| Many Emails Per User (1-to-many) | SQL JOIN with Emails Table | Embed relevant email doc in User Document |\n",
    "| Many Items Owned by Many Users (many-tomany) | SQL JOIN with Items Table | Programmatically Join with Items Collection |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MongoDB from Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from pymongo import MongoClient\n",
    "from pymongo.errors import ConnectionFailure\n",
    "\n",
    "def main():\n",
    "    \"\"\" Connect to MongoDB \"\"\"\n",
    "    try:\n",
    "        #Connect to Database\n",
    "        client = MongoClient(host=\"localhost\", port=27017)\n",
    "        print \"Connected successfully\"\n",
    "\n",
    "    except ConnectionFailure, e:\n",
    "        sys.stderr.write(\"Could not connect to MongoDB: %s\" % e)\n",
    "        sys.exit(1)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client = MongoClient('localhost', 27017)\n",
    "\n",
    "# The URI format\n",
    "client = MongoClient('mongodb://localhost:27017/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from pymongo import MongoClient\n",
    "from pymongo.errors import ConnectionFailure\n",
    "\n",
    "def main():\n",
    "    \"\"\" Connect to MongoDB \"\"\"\n",
    "    try:\n",
    "        #Connect to Database\n",
    "        client = MongoClient(host=\"localhost\", port=27017)\n",
    "        print \"Connected successfully\"\n",
    "        \n",
    "        # Get a Database handle to a database named \"twitterdb\"\n",
    "        dbh = client[\"twitterdb\"]\n",
    "        print \"Successfully set up a database handle\"\n",
    "        \n",
    "    except ConnectionFailure, e:\n",
    "        sys.stderr.write(\"Could not connect to MongoDB: %s\" % e)\n",
    "        sys.exit(1)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "client[\"twitterdb\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "client.twitterdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create/Insert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from pymongo import MongoClient\n",
    "from pymongo.errors import ConnectionFailure\n",
    "from datetime import datetime\n",
    "\n",
    "def main():\n",
    "    \"\"\" Connect to MongoDB \"\"\"\n",
    "    try:\n",
    "        #Connect to Database\n",
    "        client = MongoClient(host=\"localhost\", port=27017)\n",
    "        print \"Connected successfully\"\n",
    "        \n",
    "        # Get a Database handle to a database named \"twitterdb\"\n",
    "        dbh = client[\"twitterdb\"]\n",
    "        #assert dbh.connection == c\n",
    "        print \"Successfully set up a database handle\"\n",
    "        \n",
    "    except ConnectionFailure, e:\n",
    "        sys.stderr.write(\"Could not connect to MongoDB: %s\" % e)\n",
    "        sys.exit(1)\n",
    "        \n",
    "    user_doc = {\n",
    "        \"username\" : \"janedoe\",\n",
    "        \"firstname\" : \"Jane\",\n",
    "        \"surname\" : \"Doe\",\n",
    "        \"dateofbirth\" : datetime(1974, 4, 12),\n",
    "        \"email\" : \"janedoe74@example.com\",\n",
    "        \"score\" : 0\n",
    "        }\n",
    "    dbh.users.insert_one(user_doc)\n",
    "    print \"Successfully inserted document: %s\" % user_doc\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes**\n",
    "* The PyMongo driver supports Python datetime objects (it'll translate between mongodb datetime objects and python datatime objects), which is great for us. We'll not have to translate between the two data structures.\n",
    "* Just like we noted before, we don't have to create our collection “users” before we insert documents to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = client.twitterdb.users.insert_one({\n",
    "    \"username\" : \"Pavitra\",\n",
    "    \"firstname\" : \"Pavitra\",\n",
    "    \"surname\" : \"Pravakar\",\n",
    "    \"dateofbirth\" : datetime(1986, 4, 12),\n",
    "    \"email\" : \"spiderman@marvelheroes.com\",\n",
    "    \"score\" : 0\n",
    "})\n",
    "result.inserted_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_doc = client.twitterdb.users.find_one({\"username\" : \"janedoe\"})\n",
    "if not user_doc:\n",
    "    print \"no document found for username janedoe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "users = client.twitterdb.users.find({\"username\":\"janedoe\"})\n",
    "for user in users:\n",
    "    print user.get(\"email\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_doc = {\n",
    "    \"username\" : \"janedoe\",\n",
    "    \"firstname\" : \"Jane\",\n",
    "    \"surname\" : \"Doe\",\n",
    "    \"dateofbirth\" : datetime(1974, 4, 12),\n",
    "    \"email\" : \"janedoe74@example.com\",\n",
    "    \"score\" : 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# first query to get a copy of the current document\n",
    "import copy\n",
    "old_user_doc = client.twitterdb.users.find_one({\"username\":\"janedoe\"})\n",
    "new_user_doc = copy.deepcopy(old_user_doc)\n",
    "\n",
    "# modify the copy to change the email address\n",
    "new_user_doc[\"email\"] = \"janedoe74@example2.com\"\n",
    "\n",
    "# run the update query\n",
    "# replace the matched document with the contents of new_user_doc\n",
    "client.twitterdb.users.replace_one({\"username\":\"janedoe\"}, new_user_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the whole replacement document can be cumbersome, and worse, can introduce race conditions. Imagine you want to increment the score property of the “janedoe” user. In order to achieve this with the replacement approach, you would have to first fetch the document, modify it with the incremented score, then write it back to\n",
    "the database. With that approach, you could easily lose other score changes if something else were to update the score in between you reading and writing it.\n",
    "\n",
    "In order to solve this problem, the update document supports an additional set of MongoDB operators called “update modifiers”. These update modifiers include operators such as atomic increment/decrement, atomic list push/pop and so on. It is very helpful to be aware of which update modifiers are available and what they can do when\n",
    "designing your application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "client.twitterdb.users.update_one({\"username\":\"janedoe\"},\n",
    "                {\"$set\":{\"email\":\"janedoe74@example2.com\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "client.twitterdb.users.update_one({\"username\":\"janedoe\"},\n",
    "                 {\"$set\":{\"email\":\"janedoe74@example2.com\", \"score\":1}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = client.twitterdb.users.update_one({\"username\":\"janedoe\"},\n",
    "                 {\"$set\":{\"email\":\"janedoe74@exple2.com\", \"score\":1}})\n",
    "result.modified_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "client.twitterdb.users.delete_one({\"score\":1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Twitter API in Action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organization of Twitter Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"teamindia_tweet.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Tweet contains:\n",
    "* date and time\n",
    "* links\n",
    "* user mentions (@)\n",
    "* hash tags (#)\n",
    "* retweets count\n",
    "* locale language\n",
    "* favorites count\n",
    "* geocode\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing Twitter Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REST API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Twitter REST API Documentation](https://dev.twitter.com/rest/public)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Twitter Streaming API Documentation](https://dev.twitter.com/streaming/overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OAuth\n",
    "\n",
    "* [Twitter OAuth Documentation](https://dev.twitter.com/oauth)\n",
    "* Instructions for getting access:\n",
    "    - Create a Twitter account\n",
    "    - Go to https://apps.twitter.com/\n",
    "    - Create New App (button on top right corner(-ish))\n",
    "    - Fill out details in the next page. Value of *Website* doesn't matter right now (use http://google.com). Create your Twitter application.\n",
    "    - In the next screen, select the *KeyandAccessTokens* tab.\n",
    "    - Note down the following credentials:\n",
    "        * Consumer Key (API Key)\n",
    "        * Consumer Secret (API Secret)\n",
    "    - Click on *Create my access token*. After tokens are generated, note down the following credentials:\n",
    "        * Access Token\n",
    "        * Access Token Secret\n",
    "    - Add the credentials to *.profile*\n",
    "        * .profile vs .bashrc vs .Renviron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Twython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    pip install twython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Official Twython Documentation](https://twython.readthedocs.org/en/latest/)\n",
    "* Supports both REST and Streaming APIs\n",
    "* For more wrappers, see https://dev.twitter.com/overview/api/twitter-libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching by Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "TWITTER_CONSUMER_KEY = os.environ[\"TWITTER_CONSUMER_KEY\"]\n",
    "TWITTER_CONSUMER_SECRET = os.environ[\"TWITTER_CONSUMER_SECRET\"]\n",
    "TWITTER_ACCESS_TOKEN = os.environ[\"TWITTER_ACCESS_TOKEN\"]\n",
    "TWITTER_ACCESS_TOKEN_SECRET = os.environ[\"TWITTER_ACCESS_TOKEN_SECRET\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from twython import Twython\n",
    "twitter = Twython(TWITTER_CONSUMER_KEY, TWITTER_CONSUMER_SECRET, TWITTER_ACCESS_TOKEN, TWITTER_ACCESS_TOKEN_SECRET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = twitter.search(q=\"Salman Khan\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**\n",
    "* If Twython fails to authenticate, result will have the following json as its value:\n",
    "        {\"errors\":[{\"message\":\"Bad Authentication data\", \"code\":215}]}\n",
    "* If successful, Twython will convert the JSON it receives to a native python object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for status in result[\"statuses\"]:\n",
    "    print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for status in result[\"statuses\"]:\n",
    "    print(\"user: {0} text: {1}\".format(status[\"user\"][\"name\"], \n",
    "                                       status[\"text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = twitter.search(q=\"data science\")\n",
    "for status in result[\"statuses\"]:\n",
    "    print(\"user: {0} \\n text: {1} \\n\".format(status[\"user\"][\"name\"].encode(\"utf-8\"), \n",
    "                                             status[\"text\"].encode(\"utf-8\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More documentation at https://dev.twitter.com/rest/reference/get/search/tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving Timeline (your own)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "timeline = twitter.get_home_timeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for tweet in timeline:\n",
    "    print(\" User: {0} \\n Created: {1} \\n Text: {2} \\n\".format(tweet[\"user\"][\"name\"].encode(\"utf-8\"), \n",
    "                                                            tweet[\"created_at\"].encode(\"utf-8\"), \n",
    "                                                            tweet[\"text\"].encode(\"utf-8\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving Timeline (other users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tl = twitter.get_user_timeline(screen_name = \"iamsrk\", count = 5)\n",
    "for tweet in tl:\n",
    "    print(\" User: {0} \\n Created: {1} \\n Text: {2} \\n\".format(tweet[\"user\"][\"name\"].encode(\"utf-8\"),\n",
    "                                                            tweet[\"created_at\"].encode(\"utf-8\"),\n",
    "                                                            tweet[\"text\"].encode(\"utf-8\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Official Documentation for home timeline](https://dev.twitter.com/rest/reference/get/statuses/home_timeline)\n",
    "* [Offician Documentation for (other) user timeline](https://dev.twitter.com/rest/reference/get/statuses/user_timeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a list of followers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "followers = twitter.get_followers_list(screen_name=\"dataBiryani\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for follower in followers[\"users\"]:\n",
    "    print(\" {0} \\n \".format(follower))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for follower in followers[\"users\"]:\n",
    "    print(\" user: {0} \\n name: {1} \\n Number of tweets: {2} \\n\".format(follower[\"screen_name\"],\n",
    "                                                                       follower[\"name\"],\n",
    "                                                                       follower[\"statuses_count\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setiment Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Sentiment Classification?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment classification is a special task of text classification whose objective is to classify a text according to the sentimental polarities of opinions it contains - favorable or unfavorable, positive or negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"sentiment_classification_process.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affective Norms for English Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  The ANEW provides a set of normative emotional ratings as a text corpus for a large number of words in the English language.\n",
    "* These sets of verbal materials have been rated in terms of pleasure, arousal, and dominance, in order to create a standard for use in studies of emotion and attention."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Sentiment140"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* http://help.sentiment140.com/for-students\n",
    "* Download link\n",
    "    - http://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip\n",
    "    - (mirror) https://docs.google.com/file/d/0B04GJPshIjmPRnZManQwWEdTZjg/edit\n",
    "* The data has been processed so that the emoticons are stripped off.\n",
    "* CSV format\n",
    "* Data file format has 6 fields:\n",
    "    - 0 - the polarity of the tweet (0 = negative, 2 = neutral, 4 = positive)\n",
    "    - 1 - the id of the tweet (2087)\n",
    "    - 2 - the date of the tweet (Sat May 16 23:58:44 UTC 2009)\n",
    "    - 3 - the query (lyx). If there is no query, then this value is NO_QUERY.\n",
    "    - 4 - the user that tweeted (robotickilldozr)\n",
    "    - 5 - the text of the tweet (Lyx is cool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#FINAL ALGORITHM\n",
    "#Feed negative and positive tweets to the classification function for training. (using the Sentiment140 dataset)\n",
    "#storing the training data in a dictinary\n",
    "import nltk\n",
    "import csv\n",
    "with open('training.1600000.processed.noemoticon.csv', 'rb') as csvfile:\n",
    "    twit = csv.reader(csvfile)\n",
    "    labels=['sentiment','id','date','query','user','tweettext']\n",
    "    i=0\n",
    "    dict={}\n",
    "    for row in twit:\n",
    "        temp={}\n",
    "        k=0\n",
    "        for j in labels:\n",
    "            v=row[k]\n",
    "            temp[j]=v\n",
    "            k=k+1\n",
    "        dict[i]=temp\n",
    "        i=i+1\n",
    "    for x in dict:\n",
    "        indicts=dict.values()\n",
    "\n",
    "\n",
    "    negativeTweets=[]\n",
    "    positiveTweets=[]\n",
    "  \n",
    "    for val in indicts:\n",
    "        if int(val['sentiment'])==4:\n",
    "            positiveTweets.append(val['tweettext'])\n",
    "        \n",
    "        elif int(val['sentiment'])==0:\n",
    "            negativeTweets.append(val['tweettext'])\n",
    "            \n",
    "    \n",
    "#below code is to make a list of positive tweets and negative tweets  \n",
    "    pos_tweets=[]\n",
    "    for i in range(len(positiveTweets)):\n",
    "        pos_tweets.append('positive')\n",
    "    \n",
    "    neg_tweets=[]\n",
    "    for i in range(len(negativeTweets)):\n",
    "        neg_tweets.append('negative')\n",
    "    \n",
    "    pos_vale=zip(positiveTweets,pos_tweets)\n",
    "    print pos_vale[147]\n",
    "    \n",
    "    neg_vale=zip(negativeTweets,neg_tweets)\n",
    "    print neg_vale[121]\n",
    "\n",
    "#below code is used for combining both negative and positive tweet with its sentiment which contains only those words which \n",
    "#have more 3 or more characters(eg removing ---- in,of,at,it etc)\n",
    "    tweets = []\n",
    "    for (words, sentiment) in pos_vale + neg_vale:\n",
    "        words_filtered = [e.lower() for e in words.split() if len(e) >= 3]\n",
    "        tweets.append((words_filtered, sentiment))\n",
    "    print tweets[163]\n",
    "\n",
    "#creating a bag of all the words in the tweets which has words which are repeated\n",
    "    def bagOfWords(tweets):\n",
    "        all_words = []\n",
    "        for (words, sentiment) in tweets:\n",
    "            all_words.extend(words)\n",
    "        return all_words\n",
    "    \n",
    "#creating a list of unique words     \n",
    "    def wordFeatures(wordlist):\n",
    "        wordlist = nltk.FreqDist(wordlist)\n",
    "#above variable wordlist has a set of keys which are the words and values which are the number of times it has occured\n",
    "        word_features = wordlist.keys()\n",
    "        return word_features\n",
    "    \n",
    "    word_features = wordFeatures(bagOfWords(tweets))\n",
    "#above variable contains a list of unique words    \n",
    "\n",
    "    \n",
    "    def getFeatures(doc):\n",
    "        document_words = set(doc)\n",
    "        features = {}\n",
    "        for word in word_features:\n",
    "            features['contains(%s)' % word] = (word in document_words)\n",
    "        return features    \n",
    "#above function returns a dictionary which lists only those words as true which are present in doc and word_features\n",
    "\n",
    "    training = nltk.classify.apply_features(getFeatures, tweets)\n",
    "    print training[346][1]\n",
    "    print type(training)\n",
    "    \n",
    "#The variable ‘training’ contains the labeled feature sets. It is a list of tuples which each tuple containing the feature \n",
    "#dictionary and the sentiment string for each tweet. The sentiment string is also called ‘label’. \n",
    "    \n",
    "    classifier = nltk.NaiveBayesClassifier.train(training)\n",
    "    print type(classifier)\n",
    "    \n",
    "    print(classifier.show_most_informative_features(32))\n",
    "    \n",
    "#trying out example on classifier     \n",
    "    tweeteg = 'this is not good,this is very bad'\n",
    "    print classifier.classify(getFeatures(tweeteg.split()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predicting Sentiment of new Tweets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# What Next?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## The Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Write a blog post on how to use **OR** operator for find queries in mongodb.\n",
    "2. Feed negative and positive tweets to the classification function for training. (using the Sentiment140 dataset)\n",
    "3. Crawl all followers of ***naveen_odisha***, Odisha CM (note: you'll have to pay attention to rate limiting)\n",
    "4. Crawl all followers of SRK. How can you calculate if this is feasible or not? (show the math)\n",
    "5. Predict the sentiment of tweets by followers of ***naveen_odisha*** "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
